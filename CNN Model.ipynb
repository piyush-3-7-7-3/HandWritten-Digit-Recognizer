{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2496d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 30s 502us/step - loss: 0.1711 - accuracy: 0.9457\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0466 - accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.0314 - accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 34s 558us/step - loss: 0.0242 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 34s 564us/step - loss: 0.0185 - accuracy: 0.9941\n",
      "10000/10000 [==============================] - 2s 190us/step\n",
      "0.9908000230789185\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#importing the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#adding the parameters in the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#converting the data into useable format\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "#compiling and fitting the data in model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "#calculating accuracy and loss\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(test_acc)\n",
    "\n",
    "#saving the model\n",
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e0fb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 194us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03358749564248665, 0.9908000230789185]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evalutaing the model on test dataset\n",
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed7eb20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the model performance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image_index = 2853\n",
    "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
    "predict = test_images[image_index].reshape(28,28)\n",
    "pred = model.predict(test_images[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730ad52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
